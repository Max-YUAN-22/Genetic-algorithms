#!/usr/bin/env python3
"""
Kaggle Notebookæ¨¡æ¿ - RSNA Intracranial Aneurysm Detection
åŸºäºç°æœ‰0.69ä»£ç ï¼Œé›†æˆæˆ‘ä»¬çš„å¤šæ¨¡æ€èåˆæ¨¡å‹
"""

# =============================================================================
# å¯¼å…¥å¿…è¦çš„åº“
# =============================================================================
import os
import sys
import json
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from sklearn.metrics import roc_auc_score
import cv2
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
# =============================================================================
class RSNADataset(Dataset):
    """RSNAæ•°æ®é›†ç±»"""
    def __init__(self, data_dir, mode='train', transform=None):
        self.data_dir = data_dir
        self.mode = mode
        self.transform = transform
        self.samples = self._load_samples()
        
    def _load_samples(self):
        """åŠ è½½æ ·æœ¬åˆ—è¡¨"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´
        samples = []
        # ç¤ºä¾‹å®ç°
        return samples
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        # å®ç°æ•°æ®åŠ è½½é€»è¾‘
        pass

# =============================================================================
# å¤šæ¨¡æ€èåˆæ¨¡å‹
# =============================================================================
class MultimodalFusionModel(nn.Module):
    """å¤šæ¨¡æ€èåˆæ¨¡å‹ - åŸºäºæˆ‘ä»¬çš„æ¡†æ¶"""
    def __init__(self, num_classes=14):
        super().__init__()
        
        # å¤šæ¨¡æ€ç‰¹å¾æå–å™¨
        self.cta_extractor = self._create_feature_extractor()
        self.mra_extractor = self._create_feature_extractor()
        self.t1_extractor = self._create_feature_extractor()
        self.t2_extractor = self._create_feature_extractor()
        
        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=8)
        
        # èåˆå±‚
        self.fusion = nn.Sequential(
            nn.Linear(256 * 4, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
        
    def _create_feature_extractor(self):
        """åˆ›å»ºç‰¹å¾æå–å™¨"""
        return nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten()
        )
    
    def forward(self, cta, mra, t1, t2):
        """å‰å‘ä¼ æ’­"""
        # ç‰¹å¾æå–
        cta_feat = self.cta_extractor(cta)
        mra_feat = self.mra_extractor(mra)
        t1_feat = self.t1_extractor(t1)
        t2_feat = self.t2_extractor(t2)
        
        # ç‰¹å¾èåˆ
        features = torch.stack([cta_feat, mra_feat, t1_feat, t2_feat], dim=1)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attended_features, _ = self.attention(features, features, features)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        fused_features = attended_features.mean(dim=1)
        
        # åˆ†ç±»
        output = self.fusion(fused_features)
        
        return output

# =============================================================================
# è®­ç»ƒå’ŒéªŒè¯å‡½æ•°
# =============================================================================
def train_epoch(model, dataloader, optimizer, criterion, device):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    
    for batch_idx, (data, target) in enumerate(dataloader):
        # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
        cta, mra, t1, t2 = data
        cta, mra, t1, t2 = cta.to(device), mra.to(device), t1.to(device), t2.to(device)
        target = target.to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        output = model(cta, mra, t1, t2)
        loss = criterion(output, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        if batch_idx % 100 == 0:
            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')
    
    return total_loss / len(dataloader)

def validate(model, dataloader, criterion, device):
    """éªŒè¯æ¨¡å‹"""
    model.eval()
    total_loss = 0
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for data, target in dataloader:
            # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            cta, mra, t1, t2 = data
            cta, mra, t1, t2 = cta.to(device), mra.to(device), t1.to(device), t2.to(device)
            target = target.to(device)
            
            # å‰å‘ä¼ æ’­
            output = model(cta, mra, t1, t2)
            loss = criterion(output, target)
            
            total_loss += loss.item()
            
            # æ”¶é›†é¢„æµ‹ç»“æœ
            predictions = torch.sigmoid(output)
            all_predictions.append(predictions.cpu().numpy())
            all_targets.append(target.cpu().numpy())
    
    # è®¡ç®—AUC
    all_predictions = np.concatenate(all_predictions, axis=0)
    all_targets = np.concatenate(all_targets, axis=0)
    
    auc_scores = []
    for i in range(all_targets.shape[1]):
        if np.sum(all_targets[:, i]) > 0:  # ç¡®ä¿æœ‰æ­£æ ·æœ¬
            auc = roc_auc_score(all_targets[:, i], all_predictions[:, i])
            auc_scores.append(auc)
    
    mean_auc = np.mean(auc_scores) if auc_scores else 0.0
    
    return total_loss / len(dataloader), mean_auc

# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RSNA Intracranial Aneurysm DetectionéªŒè¯...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®è·¯å¾„
    data_dir = "/kaggle/input/rsna-intracranial-aneurysm-detection"
    
    # åˆ›å»ºæ¨¡å‹
    model = MultimodalFusionModel(num_classes=14).to(device)
    print("âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # æ•°æ®åŠ è½½å™¨
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´
    train_dataset = RSNADataset(data_dir, mode='train')
    val_dataset = RSNADataset(data_dir, mode='val')
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    
    print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
    
    # è®­ç»ƒå¾ªç¯
    best_auc = 0.0
    for epoch in range(10):  # å¿«é€ŸéªŒè¯ï¼Œåªè®­ç»ƒ10ä¸ªepoch
        print(f"\nğŸ“Š Epoch {epoch+1}/10")
        
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}")
        
        # éªŒè¯
        val_loss, val_auc = validate(model, val_loader, criterion, device)
        print(f"éªŒè¯æŸå¤±: {val_loss:.4f}")
        print(f"éªŒè¯AUC: {val_auc:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_auc > best_auc:
            best_auc = val_auc
            torch.save(model.state_dict(), 'best_model.pth')
            print(f"ğŸ‰ æ–°çš„æœ€ä½³AUC: {best_auc:.4f}")
    
    print(f"\nğŸ¯ æœ€ç»ˆæœ€ä½³AUC: {best_auc:.4f}")
    
    # ç”Ÿæˆæäº¤æ–‡ä»¶
    generate_submission(model, device)
    
    return best_auc

def generate_submission(model, device):
    """ç”Ÿæˆæäº¤æ–‡ä»¶"""
    print("ğŸ“ ç”Ÿæˆæäº¤æ–‡ä»¶...")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_dataset = RSNADataset("/kaggle/input/rsna-intracranial-aneurysm-detection", mode='test')
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    model.eval()
    all_predictions = []
    all_ids = []
    
    with torch.no_grad():
        for data, ids in test_loader:
            # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            cta, mra, t1, t2 = data
            cta, mra, t1, t2 = cta.to(device), mra.to(device), t1.to(device), t2.to(device)
            
            # å‰å‘ä¼ æ’­
            output = model(cta, mra, t1, t2)
            predictions = torch.sigmoid(output)
            
            all_predictions.append(predictions.cpu().numpy())
            all_ids.extend(ids)
    
    # åˆ›å»ºæäº¤æ–‡ä»¶
    all_predictions = np.concatenate(all_predictions, axis=0)
    
    submission_data = {
        "ID": all_ids,
        "Aneurysm Present": all_predictions[:, 0],
        "Location 1": all_predictions[:, 1],
        "Location 2": all_predictions[:, 2],
        "Location 3": all_predictions[:, 3],
        "Location 4": all_predictions[:, 4],
        "Location 5": all_predictions[:, 5],
        "Location 6": all_predictions[:, 6],
        "Location 7": all_predictions[:, 7],
        "Location 8": all_predictions[:, 8],
        "Location 9": all_predictions[:, 9],
        "Location 10": all_predictions[:, 10],
        "Location 11": all_predictions[:, 11],
        "Location 12": all_predictions[:, 12],
        "Location 13": all_predictions[:, 13]
    }
    
    submission_df = pd.DataFrame(submission_data)
    submission_df.to_csv("submission.csv", index=False)
    print("âœ… æäº¤æ–‡ä»¶å·²ç”Ÿæˆ: submission.csv")

# =============================================================================
# è¿è¡Œä¸»å‡½æ•°
# =============================================================================
if __name__ == "__main__":
    best_auc = main()
    print(f"\nğŸ‰ éªŒè¯å®Œæˆï¼æœ€ä½³AUC: {best_auc:.4f}")
    print("ğŸ“ æäº¤æ–‡ä»¶: submission.csv")
    print("ğŸ“ æœ€ä½³æ¨¡å‹: best_model.pth")
